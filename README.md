<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:00D9FF,100:667EEA&height=200&section=header&text=Harsh%20Tomar&fontSize=70&fontColor=fff&animation=fadeIn&fontAlignY=38&desc=AI%20Engineer%20|%20Computer%20Vision%20|%20Generative%20AI&descAlignY=55&descSize=20"/>

</div>

<div align="center">

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Transforming Research Papers â†’ Production Systems                       â•‘
â•‘  Building AI that sees, understands, and learns                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

[![LinkedIn](https://img.shields.io/badge/-harsh--tomar-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/harsh-tomar-a96a38256/)
[![Twitter](https://img.shields.io/badge/-@kernel__crush-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://x.com/kernel_crush)
[![Portfolio](https://img.shields.io/badge/-Portfolio-FF5722?style=for-the-badge&logo=google-chrome&logoColor=white)](https://kernel-crush.netlify.app)
[![Email](https://img.shields.io/badge/-Email-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:tomarharsh28303@gmail.com)

<img src="https://komarev.com/ghpvc/?username=HarshTomar1234&label=Profile%20Views&color=00d9ff&style=flat" alt="Profile views"/>

</div>

---

<div align="center">

## About Me

</div>

**AI/ML Engineer** specializing in **Computer Vision** and **Generative AI** | B.Tech in AI & Data Science

I architect end-to-end AI systemsâ€”from implementing cutting-edge research papers in pure PyTorch to deploying production-grade solutions. My work spans computer vision pipelines, multi-agent frameworks, and LLM applications, with a focus on practical implementation over theoretical knowledge.

**Core Competencies:**

```python
expertise = {
    "computer_vision": ["Object Detection & Tracking", "Image Segmentation", 
                       "Pose Estimation", "Sports Analytics", "Medical Imaging"],
    "deep_learning": ["Vision Transformers", "LoRA/QLoRA Fine-tuning", 
                     "Vision-Language Models", "Custom Architectures"],
    "generative_ai": ["Multi-Agent Systems", "RAG Pipelines", "LLM Fine-tuning",
                     "Prompt Engineering", "AI Agents"],
    "mlops": ["Model Deployment", "API Development", "Docker", 
             "Cloud Infrastructure", "Monitoring & Logging"]
}
```

---

<div align="center">

## Technology Arsenal

<img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="700">

</div>

### Core Technologies

<p align="center">
  <img src="https://techstack-generator.vercel.app/python-icon.svg" alt="Python" width="65" height="65" />
  <img src="https://techstack-generator.vercel.app/django-icon.svg" alt="Django" width="65" height="65" />
  <img src="https://techstack-generator.vercel.app/docker-icon.svg" alt="Docker" width="65" height="65" />
  <img src="https://techstack-generator.vercel.app/github-icon.svg" alt="GitHub" width="65" height="65" />
  <img src="https://techstack-generator.vercel.app/restapi-icon.svg" alt="REST API" width="65" height="65" />
</p>

<p align="center">
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original.svg" height="50" alt="PyTorch" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/tensorflow/tensorflow-original.svg" height="50" alt="TensorFlow" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/opencv/opencv-original.svg" height="50" alt="OpenCV" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/numpy/numpy-original.svg" height="50" alt="NumPy" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pandas/pandas-original.svg" height="50" alt="Pandas" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/jupyter/jupyter-original.svg" height="50" alt="Jupyter" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" height="50" alt="VS Code" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" height="50" alt="Git" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" height="50" alt="Linux" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/googlecloud/googlecloud-original.svg" height="50" alt="Google Cloud" />
  <img width="12" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/firebase/firebase-plain.svg" height="50" alt="Firebase" />
</p>

<table align="center">
<tr>
<td align="center" width="25%">
<b>Deep Learning Frameworks</b><br><br>
PyTorch â€¢ TensorFlow â€¢ Keras<br>
Hugging Face Transformers<br>
Scikit-learn â€¢ XGBoost
</td>
<td align="center" width="25%">
<b>Computer Vision</b><br><br>
OpenCV â€¢ YOLO (v5/v8/v11)<br>
Ultralytics â€¢ Supervision<br>
Roboflow â€¢ Albumentations
</td>
<td align="center" width="25%">
<b>Generative AI & LLMs</b><br><br>
LangChain â€¢ LangGraph â€¢ CrewAI<br>
LlamaIndex â€¢ Ollama<br>
Google ADK â€¢ AutoGen
</td>
<td align="center" width="25%">
<b>MLOps & Tools</b><br><br>
Docker â€¢ Git â€¢ FastAPI<br>
Streamlit â€¢ Gradio<br>
GCP â€¢ Firebase â€¢ REST APIs
</td>
</tr>
</table>

---

<div align="center">

## Featured Projects

<img src="https://user-images.githubusercontent.com/74038190/212284115-f47cd8ff-2ffb-4b04-b5bf-4d1c14c0247f.gif" width="1000">

</div>

<div align="center">
<table>
<tr>
<td align="center" width="33%">
<img src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExYzBkN2M5NzA5ZGQ1ZTU4YzU3YzU3YzY3YzU3YzU3YzU3YzU3YzU3YzU3YyZlcD12MV9pbnRlcm5hbF9naWZzX2dpZklkJmN0PWc/3oKIPEqDGUULpEU0aQ/giphy.gif" width="150" /><br>
<b>Computer Vision</b><br>
<sub>Sports Analytics â€¢ Medical Imaging</sub>
</td>
<td align="center" width="33%">
<img src="https://media.giphy.com/media/LaVp0AyqR5bGsC5Cbm/giphy.gif" width="150" /><br>
<b>Generative AI</b><br>
<sub>Multi-Agent Systems â€¢ RAG</sub>
</td>
<td align="center" width="33%">
<img src="https://media.giphy.com/media/l0HlNaQ6gWfllcjDO/giphy.gif" width="150" /><br>
<b>Research</b><br>
<sub>ViT â€¢ LoRA â€¢ VLMs</sub>
</td>
</tr>
</table>
</div>

### Production Computer Vision Systems

<details open>
<summary><b>ğŸ¾ Tennis Vision - Advanced Sports Analytics Platform</b></summary>
<br>

**End-to-end computer vision system for professional tennis match analysis**

Real-world implementation of multiple CV techniques including object detection, tracking, and trajectory prediction for automated sports analytics.

```
Key Features:
â”œâ”€â”€ Multi-player tracking with Re-identification
â”œâ”€â”€ Ball trajectory prediction & speed calculation
â”œâ”€â”€ Court keypoint detection & perspective transform
â”œâ”€â”€ Automated shot classification (forehand/backhand/serve)
â””â”€â”€ Real-time performance metrics dashboard
```

**Technical Implementation:** YOLOv8 for detection | ByteTrack for multi-object tracking | OpenCV for image processing | Custom CNN for shot classification

**Impact:** Automated analysis pipeline reducing manual annotation time by 90%

[View Project â†’](https://github.com/HarshTomar1234/Tennis-Vision) | [Read Technical Deep Dive â†’](https://www.notion.so/Tennis-Vision-25b4df040c1480d1840ad41d281672f3)

</details>

<details>
<summary><b>âš½ Field Fusion - Soccer Intelligence Platform</b></summary>
<br>

**Real-time player tracking and team performance analytics for soccer**

Production-grade system for tactical analysis with camera movement compensation and automated team segmentation.

```
Pipeline Architecture:
â”œâ”€â”€ Player detection & tracking (YOLO + DeepSORT)
â”œâ”€â”€ Team segmentation (K-means clustering)
â”œâ”€â”€ Camera movement compensation
â”œâ”€â”€ Speed & distance metrics calculation
â””â”€â”€ Heatmap generation for tactical analysis
```

**Technical Stack:** YOLO | OpenCV | Supervision library | NumPy for optimization

[View Project â†’](https://github.com/HarshTomar1234/Field_Fusion)

</details>

<details>
<summary><b>ğŸ¥ Breast Cancer Predictor - Clinical ML System</b></summary>
<br>

**High-accuracy diagnostic support system for medical professionals**

Production ML system with 97.8% accuracy, featuring ensemble methods and an interactive web interface for clinical decision support.

```
System Components:
â”œâ”€â”€ Ensemble model (Random Forest + XGBoost)
â”œâ”€â”€ Feature importance analysis
â”œâ”€â”€ Interactive diagnostic dashboard
â”œâ”€â”€ Real-time prediction API
â””â”€â”€ Comprehensive medical visualization
```

**Technical Implementation:** Scikit-learn | XGBoost | Streamlit | REST API

[View Project â†’](https://github.com/HarshTomar1234/BREAST-CANCER-STREAMLIT-APP)

</details>

<details>
<summary><b>ğŸ—“ï¸ Elena Calendar Assistant - AI Agent</b></summary>
<br>

**Voice-powered intelligent agent for calendar management**

Multi-modal AI agent leveraging NLP and Google ADK for natural conversation-based calendar operations.

```
Agent Capabilities:
â”œâ”€â”€ Natural language understanding
â”œâ”€â”€ Multi-intent handling
â”œâ”€â”€ Context-aware responses
â”œâ”€â”€ Google Calendar API integration
â””â”€â”€ Voice command processing
```

**Framework:** Google Agent Development Kit | LangChain | Speech Recognition

[View Project â†’](https://github.com/HarshTomar1234/Calendar-Voice-Assistant)

</details>

<details>
<summary><b>ğŸ§¬ MoleCuQuest - Molecular Research Collaboration Platform</b></summary>
<br>

**Connecting biologists and medical researchers for collaborative molecular discovery**

Full-stack platform built with modern web technologies enabling researchers to collaborate on molecular biology projects and share findings.

```
Platform Features:
â”œâ”€â”€ Researcher collaboration tools
â”œâ”€â”€ Molecular data visualization
â”œâ”€â”€ Project management system
â”œâ”€â”€ Real-time collaboration
â””â”€â”€ Research paper integration
```

**Technical Stack:** TypeScript | React | Firebase | Node.js

[View Project â†’](https://github.com/HarshTomar1234/MoleCuQuest)

</details>

<details>
<summary><b>âœˆï¸ Travel Planner - AI-Powered Travel Assistant</b></summary>
<br>

**Intelligent multi-agent system for comprehensive travel planning**

Built using Google Agent Development Kit, this system orchestrates multiple AI agents to handle flight bookings, hotel recommendations, itinerary planning, and local attractions.

```
Agent System:
â”œâ”€â”€ Flight search agent
â”œâ”€â”€ Hotel recommendation agent
â”œâ”€â”€ Itinerary planning agent
â”œâ”€â”€ Budget optimization agent
â””â”€â”€ User preference learning
```

**Framework:** Google ADK | Streamlit | Multi-Agent Orchestration

[View Project â†’](https://github.com/HarshTomar1234/Travel-Planner)

</details>

---

<div align="center">

<img src="https://user-images.githubusercontent.com/74038190/229223263-cf2e4b07-2615-4f87-9c38-e37600f8381a.gif" width="400">

</div>

### Research Paper Implementations

<div align="center">

> Building research papers from scratch to understand the fundamentals

<img src="https://media.giphy.com/media/coxQHKASG60HrHtvkt/giphy.gif" width="300">

</div>

<table>
<tr>
<td width="33%">

**Vision Transformers (ViT)**

*"An Image is Worth 16x16 Words"*

Pure PyTorch implementation of the groundbreaking transformer architecture for computer vision, demonstrating patch embedding, positional encoding, and multi-head self-attention.

```python
class ViT:
    - Patch Embedding
    - Position Embedding
    - Transformer Encoder
    - MLP Head
```

[**â†’ View Implementation**](https://github.com/HarshTomar1234/vision_transformer-ViT-)

</td>
<td width="33%">

**LoRA & QLoRA**

*Memory-Efficient Fine-tuning*

From-scratch implementation of Low-Rank Adaptation techniques for efficient model fine-tuning. Demonstrates parameter-efficient training of large models with minimal memory footprint.

```python
class LoRA:
    - Low-Rank Matrices
    - 4-bit Quantization
    - Adapter Layers
    - Efficient Training
```

[**â†’ View Implementation**](https://github.com/HarshTomar1234/PyTorch-LoRA-QLoRA)

</td>
<td width="33%">

**VLMverse**

*Vision-Language Models*

Implementation of multimodal architectures (PaLiGemma, SigLIP) that bridge computer vision and NLP for unified understanding of images and text.

```python
class VLM:
    - Image Encoder
    - Text Encoder  
    - Cross-Modal Fusion
    - Joint Training
```

[**â†’ View Implementation**](https://github.com/HarshTomar1234/VLMverse)

</td>
</tr>
</table>

---

<div align="center">

<img src="https://user-images.githubusercontent.com/74038190/212257472-08e52665-c503-4bd9-aa20-f5a4dae769b5.gif" width="100">

### Multi-Agent Systems & AI Frameworks

<img src="https://media.giphy.com/media/L1R1tvI9svkIWwpVYr/giphy.gif" width="500">

</div>

| Framework | Focus | Key Features | Repository |
|-----------|-------|-------------|------------|
| **AgentForge** | Multi-agent orchestration with CrewAI, LangGraph, PhiData | Agent communication, Task delegation, Workflow automation | [View Code â†’](https://github.com/HarshTomar1234/AgentForge) |
| **Google ADK** | Agent Development Kit for production AI agents | Production-ready agents, Google integration, Scalable architecture | [View Code â†’](https://github.com/HarshTomar1234/Google-Agent-Development-kit-ADK-) |
| **MCP Protocol** | Model Context Protocol server implementations | Context management, Protocol design, Server architecture | [View Code â†’](https://github.com/HarshTomar1234/mcp-servers-experiments) |
| **Travel Planner** | Multi-agent travel planning system with Google ADK | Multi-agent coordination, Travel API integration, Smart recommendations | [View Code â†’](https://github.com/HarshTomar1234/Travel-Planner) |

---

<div align="center">

<img src="https://user-images.githubusercontent.com/74038190/212257467-871d32b7-e401-42e8-a166-fcfd7baa4c6b.gif" width="100">

## Learning & Knowledge Repositories

*Comprehensive implementations from fundamentals to production*

</div>

<p align="center">
  <img src="https://media.giphy.com/media/qgQUggAC3Pfv687qPC/giphy.gif" width="400">
  <img src="https://media.giphy.com/media/3oKIPEqDGUULpEU0aQ/giphy.gif" width="400">
</p>

<table>
<tr>
<td width="50%">

### Machine Learning & Deep Learning

Complete implementation suite covering classical ML algorithms, neural networks, CNNs, RNNs, and transformer architectures with production-ready code.

**Covers:**
- Classical ML (Linear Regression, SVM, Decision Trees)
- Neural Networks (MLP, CNN, RNN, LSTM, GRU)
- Transformers & Attention Mechanisms
- NLP Fundamentals & Advanced Techniques

[ğŸ“š Explore Repository â†’](https://github.com/HarshTomar1234/Machine-and-Deep-Learning-NLP)

</td>
<td width="50%">

### Computer Vision

End-to-end CV implementations including object detection, semantic segmentation, instance segmentation, pose estimation, and tracking algorithms.

**Covers:**
- Object Detection (RCNN, YOLO, SSD)
- Semantic & Instance Segmentation
- Pose Estimation & Tracking
- Image Classification & Feature Extraction

[ğŸ‘ï¸ Explore Repository â†’](https://github.com/HarshTomar1234/Computer-Vision)

</td>
</tr>
<tr>
<td width="50%">

### PyTorch Deep Dive

From tensor operations to custom architectures, covering training loops, optimization strategies, and production deployment patterns.

**Covers:**
- Tensor Operations & Autograd
- Custom Layers & Architectures
- Training Loops & Optimization
- Model Deployment & Serving

[ğŸ”¥ Explore Repository â†’](https://github.com/HarshTomar1234/torchquest)

</td>
<td width="50%">

### RAG Systems

Retrieval-Augmented Generation implementations with vector databases, embedding strategies, and production RAG pipelines.

**Covers:**
- Vector Databases (Pinecone, Chroma, FAISS)
- Embedding Strategies
- Retrieval Techniques
- Production RAG Pipelines

[ğŸ” Explore Repository â†’](https://github.com/HarshTomar1234/RAGify)

</td>
</tr>
</table>

---

<div align="center">

### Additional Projects & Explorations

<img src="https://media.giphy.com/media/kH6CqYiquZawmU1HI6/giphy.gif" width="400">

</div>

<table>
<tr>
<td width="33%" align="center">

**Deep Learning Notebooks**

Hands-on implementations of various deep learning concepts, architectures, and techniques with detailed explanations.

[View â†’](https://github.com/HarshTomar1234)

</td>
<td width="33%" align="center">

**ML Algorithms from Scratch**

Building machine learning algorithms from first principles to understand the mathematics behind them.

[View â†’](https://github.com/HarshTomar1234)

</td>
<td width="33%" align="center">

**Computer Vision Projects**

Collection of CV projects including object detection, tracking, segmentation, and image processing.

[View â†’](https://github.com/HarshTomar1234/Computer-Vision)

</td>
</tr>
</table>

---

<div align="center">

## GitHub Analytics

<img src="https://user-images.githubusercontent.com/74038190/212257454-16e3712e-945a-4ca2-b238-408ad0bf87e6.gif" width="100">
<img src="https://user-images.githubusercontent.com/74038190/212257472-08e52665-c503-4bd9-aa20-f5a4dae769b5.gif" width="100">
<img src="https://user-images.githubusercontent.com/74038190/212257468-1e9a91f1-b626-4baa-b15d-5c385dfa7ed2.gif" width="100">
<img src="https://user-images.githubusercontent.com/74038190/212257465-7ce8d493-cac5-494e-982a-5a9deb852c4b.gif" width="100">
<img src="https://user-images.githubusercontent.com/74038190/212257460-738ff738-247f-4445-a718-cdd0ca76e2db.gif" width="100">

</div>

<br>

<div align="center">
<img src="https://github-readme-activity-graph.vercel.app/graph?username=HarshTomar1234&custom_title=Contribution%20Graph&bg_color=0D1117&color=00D9FF&line=667EEA&point=00D9FF&area_color=0D1117&area=true&hide_border=true" />
</div>

<br>

<p align="center">
<img height="180em" src="https://github-readme-stats.vercel.app/api?username=HarshTomar1234&show_icons=true&theme=react&include_all_commits=true&count_private=true&hide_border=true&bg_color=0D1117&title_color=00D9FF&icon_color=00D9FF&text_color=fff"/>
<img height="180em" src="https://github-readme-streak-stats.herokuapp.com?user=HarshTomar1234&theme=react&hide_border=true&background=0D1117&ring=00D9FF&fire=00D9FF&currStreakLabel=00D9FF"/>
</p>

<br>

<p align="center">
<img height="180em" src="https://github-readme-stats.vercel.app/api/top-langs/?username=HarshTomar1234&layout=compact&langs_count=8&theme=react&hide_border=true&bg_color=0D1117&title_color=00D9FF&text_color=fff&icon_color=00D9FF" />
</p>

<br>

<div align="center">
<img src="https://github-profile-trophy.vercel.app/?username=HarshTomar1234&theme=discord&no-frame=true&no-bg=true&column=7&margin-w=15&margin-h=15" />
</div>

<br>

<div align="center">

**47 Public Repositories** | **369 Stars Earned** | **Active Contributor**

<img src="https://media.giphy.com/media/W5eoZHPpUx9sapR0eu/giphy.gif" width="30px" alt="Git"/>

</div>

---

<div align="center">

<img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400">

## Technical Writing

</div>

I document implementation details, architecture decisions, and insights from building AI systems:

<table>
<tr>
<td width="50%">

**[Tennis Vision: Deep Dive into Sports Computer Vision](https://www.notion.so/Tennis-Vision-25b4df040c1480d1840ad41d281672f3)**

*System architecture, multi-object tracking challenges, and real-time performance optimization*

- YOLOv8 implementation details
- Multi-object tracking algorithms
- Real-time processing optimization
- Computer vision pipeline design

</td>
<td width="50%">

**[Reasoning in LLMs from Scratch](https://www.notion.so/Core-Concepts-of-Reasoning-in-LLMs-from-Scratch-1de4df040c14804b9b64f034e181aa75)**

*Understanding emergent reasoning capabilities and chain-of-thought mechanisms*

- Chain-of-thought prompting
- Reasoning architectures
- LLM capabilities analysis
- Practical applications

</td>
</tr>
</table>

---

<div align="center">

<img src="https://user-images.githubusercontent.com/74038190/212284087-bbe7e430-757e-4901-90bf-4cd2ce3e1852.gif" width="100">

## Current Focus

</div>

<table>
<tr>
<td width="50%">

### Production ML & Computer Vision

```python
current_projects = {
    "cv_pipelines": [
        "Edge deployment optimization",
        "Real-time object detection",
        "Multi-camera tracking systems"
    ],
    "mlops": [
        "Model monitoring & logging",
        "A/B testing frameworks",
        "CI/CD for ML models"
    ]
}
```

</td>
<td width="50%">

### Research & Innovation

```python
research_interests = {
    "vision_language": [
        "PaLiGemma, SigLIP implementations",
        "Multimodal understanding"
    ],
    "efficient_ai": [
        "LoRA/QLoRA fine-tuning",
        "Model quantization",
        "Knowledge distillation"
    ],
    "agentic_ai": [
        "LangGraph workflows",
        "Google ADK applications",
        "Multi-agent systems"
    ]
}
```

</td>
</tr>
</table>

---

<div align="center">

## 3D Contribution Visualization ğŸ§ 

<img src="https://media.giphy.com/media/3oKIPEqDGUULpEU0aQ/giphy.gif" width="100">

### Interactive 3D Contribution Landscape

*Your contributions visualized as a stunning 3D neural terrain - where each peak represents deep learning in action*

<img src="https://raw.githubusercontent.com/HarshTomar1234/HarshTomar1234/main/profile-3d-contrib/profile-night-rainbow.svg" width="100%">

<br>

<table>
<tr>
<td width="50%" align="center">

### ğŸ”¥ Neural Network in Action

<img src="https://user-images.githubusercontent.com/74038190/225813708-98b745f2-7d22-48cf-9150-083f1b00d6c9.gif" width="500">

**Input Layer â†’ Hidden Layers â†’ Output Layer**

*Processing contributions through deep neural networks*

</td>
<td width="50%" align="center">

### ğŸ¯ Computer Vision Pipeline

<img src="https://user-images.githubusercontent.com/74038190/212257472-08e52665-c503-4bd9-aa20-f5a4dae769b5.gif" width="100">

```mermaid
graph TD
    A[ğŸ“Š GitHub Contributions] --> B[ğŸ” Feature Extraction]
    B --> C[ğŸ¨ Image Processing]
    C --> D[ğŸ§  Neural Network]
    D --> E[ğŸ¯ Object Detection]
    E --> F[ğŸ“ˆ Model Deployment]
    F --> G[ğŸš€ Production]
    
    style A fill:#00D9FF,stroke:#667EEA,stroke-width:3px,color:#000
    style D fill:#667EEA,stroke:#00D9FF,stroke-width:3px,color:#fff
    style G fill:#00D9FF,stroke:#667EEA,stroke-width:3px,color:#000
```

</td>
</tr>
</table>

<br>

<div align="center">
<table>
<tr>
<td width="33%" align="center">

### ğŸ‘ï¸ Vision Transformers

<img src="https://user-images.githubusercontent.com/74038190/212257467-871d32b7-e401-42e8-a166-fcfd7baa4c6b.gif" width="80">

**Attention Mechanism**
```
Patches â†’ Embeddings
    â†“
Multi-Head Attention
    â†“
Feed Forward NN
    â†“
Classification
```

</td>
<td width="33%" align="center">

### ğŸ¯ Object Detection

<img src="https://user-images.githubusercontent.com/74038190/212257454-16e3712e-945a-4ca2-b238-408ad0bf87e6.gif" width="80">

**YOLO Pipeline**
```
Image Input
    â†“
CNN Backbone
    â†“
Detection Head
    â†“
Bounding Boxes
```

</td>
<td width="33%" align="center">

### ğŸ§¬ Deep Learning

<img src="https://user-images.githubusercontent.com/74038190/212257465-7ce8d493-cac5-494e-982a-5a9deb852c4b.gif" width="80">

**Training Loop**
```
Forward Pass
    â†“
Loss Calculation
    â†“
Backpropagation
    â†“
Optimization
```

</td>
</tr>
</table>
</div>

<br>

<div align="center">

### ğŸŒˆ Contribution Processing Through Neural Layers

<img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="600">

</div>

<br>

<p align="center">
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12&height=100&section=header&text=AI%20â—%20Computer%20Vision%20â—%20Neural%20Networks&fontSize=25&fontColor=fff&animation=twinkling" width="100%">
</p>

</div>

---

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=rect&color=0:00D9FF,100:667EEA&height=2&section=header" />

<br>

<img src="https://user-images.githubusercontent.com/74038190/216122041-518ac897-8d92-4c6b-9b3f-ca01dcaf38ee.png" alt="Fire" width="40" />
<img src="https://user-images.githubusercontent.com/74038190/212284087-bbe7e430-757e-4901-90bf-4cd2ce3e1852.gif" width="40">
<img src="https://user-images.githubusercontent.com/74038190/216122041-518ac897-8d92-4c6b-9b3f-ca01dcaf38ee.png" alt="Fire" width="40" />

## Let's Build Together

**Open to opportunities in AI/ML Engineering | Computer Vision | GenAI | MLOps**

<img src="https://media.giphy.com/media/LnQjpWaON8nhr21vNW/giphy.gif" width="60"> <em><b>I'm passionate about collaborating on challenging AI projects</b> and contributing to innovative solutions that push the boundaries of what's possible with AI.</em> <img src="https://media.giphy.com/media/LnQjpWaON8nhr21vNW/giphy.gif" width="60">

<br>
<br>

**Let's Connect:**

<p align="center">
<a href="https://www.linkedin.com/in/harsh-tomar-a96a38256/">
  <img src="https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
</a>
<a href="mailto:tomarharsh28303@gmail.com">
  <img src="https://img.shields.io/badge/Email-Reach%20Out-EA4335?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
</a>
<a href="https://kernel-crush.netlify.app">
  <img src="https://img.shields.io/badge/Portfolio-Visit-FF5722?style=for-the-badge&logo=google-chrome&logoColor=white" alt="Portfolio"/>
</a>
<a href="https://x.com/kernel_crush">
  <img src="https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white" alt="Twitter"/>
</a>
</p>

<br>

<img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="900">

<br>

### "Building AI systems that don't just workâ€”they inspire" 

<br>

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=0:00D9FF,100:667EEA&height=120&section=footer" />
</p>

</div>

